{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%gui qt\n",
    "from delta.assets import download_assets\n",
    "from delta.utilities import cfg\n",
    "from delta.data import seg_weights\n",
    "\n",
    "from skimage.morphology import erosion, disk, binary_erosion\n",
    "\n",
    "import pathlib\n",
    "import json\n",
    "import h5py\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "import tifffile\n",
    "\n",
    "import napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_str(posixpath):\n",
    "    return str(posixpath.resolve())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-21 20:41:46.643 python[21314:1216494] AdjustToIronwoodHotKeyChange - CG (hotmod:1) HotKey : hotKey enabled = 1, keyChar=0xfffbffff, virtKey=0x40000, flags=0x0 \n"
     ]
    }
   ],
   "source": [
    "#set paths\n",
    "#root = pathlib.Path(pathlib.Path.home(), 'home', 'Caulobacter')\n",
    "\n",
    "root = pathlib.Path(pathlib.Path.home(), 'Andreas', 'Delta2_Caulobacter')\n",
    "data_dir = root / 'data'\n",
    "model_dir = root / 'models'\n",
    "training_set = data_dir / 'training'\n",
    "validation_set = data_dir / 'validation'\n",
    "savefile = model_dir / 'Caulobacter2D'\n",
    "\n",
    "#path to training data\n",
    "training_file = '/Users/simonvanvliet/Andreas/Training/training_data.hdf5'\n",
    "\n",
    "#set fraction of training data to use for validation\n",
    "validation_frac = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make folders\n",
    "data_dir.mkdir(exist_ok=True)\n",
    "model_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download delta assets   \n",
    "download_assets(\n",
    "    load_models=to_str(model_dir),\n",
    "    load_sets=False,\n",
    "    load_evals=False,\n",
    "    config_level=to_str(root)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify config file\n",
    "config_filename = root / 'config_2D.json'\n",
    "with open(config_filename) as f:\n",
    "    config = json.load(f)\n",
    "    \n",
    "#point to model location\n",
    "config['model_file_seg'] = to_str(model_dir / 'unet_pads_seg.hdf5')    \n",
    "config['model_file_track'] = to_str(model_dir / 'unet_pads_track.hdf5')    \n",
    "\n",
    "#only needed for model training, in that case, point to location of training data\n",
    "config['training_set_seg'] = to_str(data_dir / 'training')\n",
    "config['training_set_track'] = ''\n",
    "\n",
    "#point to raw data location\n",
    "config['eval_movie'] = to_str(data_dir / 'evaluation')\n",
    "\n",
    "#specify output formats\n",
    "config['save_format'] = [\"pickle\", \"movie\"]    \n",
    "\n",
    "\n",
    "new_config_filename = root / 'config_2D_caulobacter.json'\n",
    "with open(new_config_filename, 'w') as f:\n",
    "    json.dump(config, f, indent=2)   \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "with h5py.File(training_file, 'r') as f:\n",
    "    labels = np.array(f['label'])\n",
    "    images = np.array(f['images'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delta trains use a binary mask as GT. If in your label image cells tend to touch, they will become merged in the mask.\n",
    "In this case it's better to first erode the cells by 1 pixel to make sure they don't touch.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process label masks\n",
    "struc = disk(1)\n",
    "\n",
    "eroded_labels = np.zeros_like(labels)\n",
    "\n",
    "for idx, lab in enumerate(labels):\n",
    "    #loop cells\n",
    "    for c in np.unique(lab):\n",
    "        if c>0:\n",
    "            eroded_labels[idx, :, :] += c * binary_erosion(lab==c, disk(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check new labels\n",
    "viewer = napari.view_image(images, name=\"phase\", colormap=\"gray\")\n",
    "viewer.add_labels(labels, name='orginal')   \n",
    "viewer.add_labels(eroded_labels, name='eroded')   \n",
    "napari.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert labels to binary mask\n",
    "gt_mask = eroded_labels > 0 \n",
    "gt_mask = gt_mask.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data in training and validation set\n",
    "rng = default_rng()\n",
    "\n",
    "n_im = labels.shape[0]\n",
    "n_val = int(np.ceil(n_im * validation_frac))  \n",
    "\n",
    "valid_set = rng.choice(n_im, size=n_val, replace=False)\n",
    "train_set = np.setdiff1d(np.arange(n_im), valid_set, assume_unique=True)\n",
    "\n",
    "mask_train = gt_mask[train_set, :, :]\n",
    "mask_valid = gt_mask[valid_set, :, :]\n",
    "\n",
    "image_train = images[train_set, :, :]\n",
    "image_valid = images[valid_set, :, :]\n",
    "\n",
    "\n",
    "training_file = data_dir /  'training_data_delta.hdf5'\n",
    "\n",
    "with h5py.File(training_file, 'w') as f:\n",
    "    f.create_dataset('mask_train', data=mask_train)\n",
    "    f.create_dataset('mask_valid', data=mask_valid)\n",
    "    f.create_dataset('image_train', data=image_train)\n",
    "    f.create_dataset('image_valid', data=image_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23, 1024, 1024)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The seg_weights function of delta is super slow, so this code will take a while to run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to interrupt the Kernel. \n",
      "No debugger available, can not send 'disconnect'. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "root = pathlib.Path(pathlib.Path.home(), 'Andreas', 'Delta2_Caulobacter')\n",
    "data_dir = root / 'data'\n",
    "\n",
    "training_file = data_dir /  'training_data_delta.hdf5'\n",
    "\n",
    "with h5py.File(training_file, 'r') as f:\n",
    "    mask_train = np.array(f['mask_train'])\n",
    "    mask_valid = np.array(f['mask_valid'])\n",
    "    image_train = np.array(f['image_train'])\n",
    "    image_valid = np.array(f['image_valid'])    \n",
    "    \n",
    "training_set = data_dir / 'training'\n",
    "validation_set = data_dir / 'validation'\n",
    "    \n",
    "training_set.mkdir(exist_ok=True)\n",
    "validation_set.mkdir(exist_ok=True)\n",
    "\n",
    "(training_set / 'img').mkdir(exist_ok=True)\n",
    "(training_set / 'seg').mkdir(exist_ok=True)\n",
    "(training_set / 'wei').mkdir(exist_ok=True)\n",
    "\n",
    "(validation_set / 'img').mkdir(exist_ok=True)\n",
    "(validation_set / 'seg').mkdir(exist_ok=True)\n",
    "(validation_set / 'wei').mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "#export training data to tiff    \n",
    "for idx, t in enumerate(train_set):\n",
    "    im_name = training_set / 'img' / ('img_%04i' % idx)\n",
    "    lab_name = training_set / 'seg' / ('img_%04i' % idx)\n",
    "    wei_name = training_set / 'wei' / ('img_%04i' % idx)\n",
    "    \n",
    "    tifffile.imwrite(im_name, np.squeeze(images[t,:,:]))\n",
    "    tifffile.imwrite(lab_name, np.squeeze(gt_mask[t,:,:]))\n",
    "    tifffile.imwrite(wei_name, seg_weights(np.squeeze(gt_mask[t,:,:])))    \n",
    "\n",
    "\n",
    "for idx, v in enumerate(valid_set):\n",
    "    im_name = validation_set / 'img' / ('img_%04i' % idx)\n",
    "    lab_name = validation_set / 'seg' / ('img_%04i' % idx)\n",
    "    wei_name = validation_set / 'wei' / ('img_%04i' % idx)\n",
    "    \n",
    "    tifffile.imwrite(im_name, np.squeeze(images[v,:,:]))\n",
    "    tifffile.imwrite(lab_name, np.squeeze(gt_mask[t,:,:]))\n",
    "    tifffile.imwrite(wei_name, seg_weights(np.squeeze(gt_mask[t,:,:])))\n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('i2i_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "04885f21a4bd9418df205c8169dbf35b8c72791b69b584ac7513023d01d78b79"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

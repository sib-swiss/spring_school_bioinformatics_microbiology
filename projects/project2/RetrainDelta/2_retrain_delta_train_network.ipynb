{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "\n",
    "from delta.assets import download_assets\n",
    "from delta.utilities import cfg\n",
    "from delta.model import unet_seg\n",
    "from delta.data import trainGenerator_seg, seg_weights\n",
    "\n",
    "import pathlib\n",
    "import json\n",
    "import h5py\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "import tifffile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_str(posixpath):\n",
    "    return str(posixpath.resolve())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#root = pathlib.Path(pathlib.Path.home(), 'home', 'Caulobacter')\n",
    "\n",
    "root = pathlib.Path(pathlib.Path.home(), 'Andreas', 'DeltaTest')\n",
    "data_dir = root / 'data'\n",
    "model_dir = root / 'models'\n",
    "\n",
    "training_file = '/Users/simonvanvliet/Andreas/Training/training_data.hdf5'\n",
    "\n",
    "validation_frac = 0.2\n",
    "\n",
    "training_set = data_dir / 'training'\n",
    "validation_set = data_dir / 'validation'\n",
    "savefile = model_dir / 'Caulobacter2D'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/simonvanvliet/I2ICourse/spring_school_bioinformatics_microbiology/projects/project2/RetrainDelta/retrain_delta2.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/simonvanvliet/I2ICourse/spring_school_bioinformatics_microbiology/projects/project2/RetrainDelta/retrain_delta2.ipynb#ch0000009?line=74'>75</a>\u001b[0m     tifffile\u001b[39m.\u001b[39mimwrite(im_name, np\u001b[39m.\u001b[39msqueeze(images[v,:,:]))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/simonvanvliet/I2ICourse/spring_school_bioinformatics_microbiology/projects/project2/RetrainDelta/retrain_delta2.ipynb#ch0000009?line=75'>76</a>\u001b[0m     tifffile\u001b[39m.\u001b[39mimwrite(lab_name, c_lab)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/simonvanvliet/I2ICourse/spring_school_bioinformatics_microbiology/projects/project2/RetrainDelta/retrain_delta2.ipynb#ch0000009?line=76'>77</a>\u001b[0m     tifffile\u001b[39m.\u001b[39mimwrite(wei_name, seg_weights(c_lab))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/simonvanvliet/I2ICourse/spring_school_bioinformatics_microbiology/projects/project2/RetrainDelta/retrain_delta2.ipynb#ch0000009?line=79'>80</a>\u001b[0m \u001b[39mfor\u001b[39;00m idx, v \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_set):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/simonvanvliet/I2ICourse/spring_school_bioinformatics_microbiology/projects/project2/RetrainDelta/retrain_delta2.ipynb#ch0000009?line=81'>82</a>\u001b[0m     im_name \u001b[39m=\u001b[39m training_set \u001b[39m/\u001b[39m \u001b[39m'\u001b[39m\u001b[39mimg\u001b[39m\u001b[39m'\u001b[39m \u001b[39m/\u001b[39m (\u001b[39m'\u001b[39m\u001b[39mimg_\u001b[39m\u001b[39m%04i\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m idx)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/i2i_p1_env/lib/python3.10/site-packages/delta/data.py:809\u001b[0m, in \u001b[0;36mseg_weights\u001b[0;34m(mask, classweights, w0, sigma)\u001b[0m\n\u001b[1;32m    807\u001b[0m distance_array \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39minf\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mones(mask\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m:\u001b[39m2\u001b[39m] \u001b[39m+\u001b[39m (\u001b[39mmax\u001b[39m(lblnb, \u001b[39m2\u001b[39m),))\n\u001b[1;32m    808\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, lblnb):\n\u001b[0;32m--> 809\u001b[0m     _, distance_array[:, :, i] \u001b[39m=\u001b[39m morph\u001b[39m.\u001b[39;49mmedial_axis(\n\u001b[1;32m    810\u001b[0m         (lblimg \u001b[39m==\u001b[39;49m i \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m) \u001b[39m==\u001b[39;49m \u001b[39m0\u001b[39;49m, return_distance\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m    811\u001b[0m     )\n\u001b[1;32m    813\u001b[0m \u001b[39m# Keep 2 smallest only:\u001b[39;00m\n\u001b[1;32m    814\u001b[0m distance_array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msort(distance_array, axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)[:, :, \u001b[39m0\u001b[39m:\u001b[39m2\u001b[39m]\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/i2i_p1_env/lib/python3.10/site-packages/skimage/morphology/_skeletonize.py:501\u001b[0m, in \u001b[0;36mmedial_axis\u001b[0;34m(image, mask, return_distance, random_state)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[39m# Determine the order in which pixels are processed.\u001b[39;00m\n\u001b[1;32m    496\u001b[0m \u001b[39m# We use a random # for tiebreaking. Assign each pixel in the image a\u001b[39;00m\n\u001b[1;32m    497\u001b[0m \u001b[39m# predictable, random # so that masking doesn't affect arbitrary choices\u001b[39;00m\n\u001b[1;32m    498\u001b[0m \u001b[39m# of skeletons\u001b[39;00m\n\u001b[1;32m    499\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m    500\u001b[0m generator \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mdefault_rng(random_state)\n\u001b[0;32m--> 501\u001b[0m tiebreaker \u001b[39m=\u001b[39m generator\u001b[39m.\u001b[39mpermutation(np\u001b[39m.\u001b[39marange(masked_image\u001b[39m.\u001b[39;49msum()))\n\u001b[1;32m    502\u001b[0m order \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlexsort((tiebreaker,\n\u001b[1;32m    503\u001b[0m                     corner_score[masked_image],\n\u001b[1;32m    504\u001b[0m                     distance))\n\u001b[1;32m    505\u001b[0m order \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mascontiguousarray(order, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mint32)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/i2i_p1_env/lib/python3.10/site-packages/numpy/core/_methods.py:48\u001b[0m, in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_sum\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     47\u001b[0m          initial\u001b[39m=\u001b[39m_NoValue, where\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m---> 48\u001b[0m     \u001b[39mreturn\u001b[39;00m umr_sum(a, axis, dtype, out, keepdims, initial, where)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "download_assets = False\n",
    "setup_processing = True\n",
    "\n",
    "#make folders\n",
    "data_dir.mkdir(exist_ok=True)\n",
    "model_dir.mkdir(exist_ok=True)\n",
    "training_set.mkdir(exist_ok=True)\n",
    "validation_set.mkdir(exist_ok=True)\n",
    "\n",
    "(training_set / 'img').mkdir(exist_ok=True)\n",
    "(training_set / 'seg').mkdir(exist_ok=True)\n",
    "(training_set / 'wei').mkdir(exist_ok=True)\n",
    "\n",
    "(validation_set / 'img').mkdir(exist_ok=True)\n",
    "(validation_set / 'seg').mkdir(exist_ok=True)\n",
    "(validation_set / 'wei').mkdir(exist_ok=True)\n",
    "    \n",
    "if download_assets:\n",
    "    #download config and default model weights\n",
    "    download_assets(\n",
    "        load_models=to_str(model_dir),\n",
    "        load_sets=False,\n",
    "        load_evals=False,\n",
    "        config_level=to_str(root)\n",
    "    )\n",
    "\n",
    "if setup_processing:    \n",
    "    # modify config file\n",
    "    config_filename = root / 'config_2D.json'\n",
    "    with open(config_filename) as f:\n",
    "        config = json.load(f)\n",
    "        \n",
    "    #point to model location\n",
    "    config['model_file_seg'] = to_str(model_dir / 'unet_pads_seg.hdf5')    \n",
    "    config['model_file_track'] = to_str(model_dir / 'unet_pads_track.hdf5')    \n",
    "\n",
    "    #only needed for model training, in that case, point to location of training data\n",
    "    config['training_set_seg'] = to_str(data_dir / 'training')\n",
    "    config['training_set_track'] = ''\n",
    "\n",
    "    #point to raw data location\n",
    "    config['eval_movie'] = to_str(data_dir / 'evaluation')\n",
    "\n",
    "    #specify output formats\n",
    "    config['save_format'] = [\"pickle\", \"movie\"]    \n",
    "\n",
    "\n",
    "    new_config_filename = root / 'config_2D_caulobacter.json'\n",
    "    with open(new_config_filename, 'w') as f:\n",
    "        json.dump(config, f, indent=2)   \n",
    "        \n",
    "        \n",
    "    #process training data\n",
    "    rng = default_rng()\n",
    "\n",
    "    with h5py.File(training_file, 'r') as f:\n",
    "        labels = np.array(f['label'])\n",
    "        images = np.array(f['images'])\n",
    "      \n",
    "    n_im = labels.shape[0]\n",
    "    n_val = int(np.ceil(n_im * validation_frac))  \n",
    "    \n",
    "    val_set = rng.choice(n_im, size=n_val, replace=False)\n",
    "    train_set = np.setdiff1d(np.arange(n_im), val_set, assume_unique=True)\n",
    "    \n",
    "    for idx, v in enumerate(val_set):\n",
    "        \n",
    "        im_name = validation_set / 'img' / ('img_%04i' % idx)\n",
    "        lab_name = validation_set / 'seg' / ('img_%04i' % idx)\n",
    "        wei_name = validation_set / 'wei' / ('img_%04i' % idx)\n",
    "        \n",
    "        c_lab = np.squeeze(labels[v,:,:]) > 0 \n",
    "        c_lab.astype(np.uint8)\n",
    "        \n",
    "        tifffile.imwrite(im_name, np.squeeze(images[v,:,:]))\n",
    "        tifffile.imwrite(lab_name, c_lab)\n",
    "        tifffile.imwrite(wei_name, seg_weights(c_lab))\n",
    "        \n",
    "        \n",
    "    for idx, v in enumerate(train_set):\n",
    "        \n",
    "        im_name = training_set / 'img' / ('img_%04i' % idx)\n",
    "        lab_name = training_set / 'seg' / ('img_%04i' % idx)\n",
    "        wei_name = training_set / 'wei' / ('img_%04i' % idx)\n",
    "        \n",
    "        c_lab = np.squeeze(labels[v,:,:]) > 0 \n",
    "        c_lab.astype(np.uint8)\n",
    "        \n",
    "        tifffile.imwrite(im_name, np.squeeze(images[v,:,:]))\n",
    "        tifffile.imwrite(lab_name, c_lab)\n",
    "        tifffile.imwrite(wei_name, seg_weights(c_lab))    \n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'img_003'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'img_%03i' % 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config:\n",
    "cfg.load_config(new_config_filename)\n",
    "\n",
    "# Training parameters:\n",
    "batch_size = 4\n",
    "epochs = 600\n",
    "steps_per_epoch = 200\n",
    "patience = 50\n",
    "\n",
    "#Data generator parameters:\n",
    "data_gen_args = dict(\n",
    "    rotation = 2,\n",
    "    rotations_90d = True,\n",
    "    zoom=.15,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    histogram_voodoo=True,\n",
    "    illumination_voodoo=True,\n",
    "    gaussian_noise = 0.03,\n",
    "    gaussian_blur = 1\n",
    "    )\n",
    "\n",
    "data_gen_args_val = dict(\n",
    "    rotation = 2,\n",
    "    rotations_90d = True,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    histogram_voodoo=True,\n",
    "    )\n",
    "\n",
    "# Generator init:\n",
    "gen_train = trainGenerator_seg(\n",
    "    batch_size,\n",
    "    os.path.join(to_str(training_set),'img'),\n",
    "    os.path.join(to_str(training_set),'seg'),\n",
    "    os.path.join(to_str(training_set),'wei'),\n",
    "    augment_params = data_gen_args,\n",
    "    target_size = cfg.target_size_seg,\n",
    "    crop_windows = cfg.crop_windows\n",
    "    )\n",
    "\n",
    "gen_validate = trainGenerator_seg(\n",
    "    batch_size,\n",
    "    os.path.join(validation_set,'img'),\n",
    "    os.path.join(validation_set,'seg'),\n",
    "    os.path.join(validation_set,'wei'),\n",
    "    augment_params = data_gen_args_val,\n",
    "    target_size = cfg.target_size_seg,\n",
    "    crop_windows = cfg.crop_windows\n",
    "    )\n",
    "\n",
    "# Define model:\n",
    "model = unet_seg(input_size = cfg.target_size_seg+(1,), pretrained_weights=cfg.model_file_seg)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks:\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    to_str(savefile), monitor='loss', verbose=2, save_best_only=True\n",
    "    )\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='loss', mode='min', verbose=2, patience=patience\n",
    "    )\n",
    "tensor_board = TensorBoard(log_dir=\"logs/cb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train:\n",
    "history = model.fit(\n",
    "    gen_train,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=epochs,\n",
    "    validation_data=gen_validate,\n",
    "    validation_steps=5,\n",
    "    callbacks=[model_checkpoint, early_stopping, tensor_board]\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 ('i2i_p1_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d42f0a35d8b9434264bb954a13c4045ab25bdf3d5d7870184404ce58dc1d3698"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

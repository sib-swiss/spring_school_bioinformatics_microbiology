{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Delta segmentation & tracking pipeline\n",
    "\n",
    "Here we will use the Delta2 package to segment and track timelapse data of microcolonies using a deep learning based workflow.  \n",
    "You can find extensive documentation on Delta [here](https://delta.readthedocs.io).\n",
    "\n",
    "In addition we will need the `json` package to edit the configuration files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import delta\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Learning networks can run on a CPU, but are much much faster on a GPU.  \n",
    "Let's see if we can use a GPU (you should see get a line with `device_type='GPU'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Folders\n",
    "Set the path to the one you used in `0_download_model_delta`.  \n",
    "We will also create a `ProcessedData` folder where we will store the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mProcessedData\u001b[m\u001b[m \u001b[34mRawData\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "root = pathlib.Path(pathlib.Path.home(), 'I2ICourse/')\n",
    "proj_dir = (root / 'Project2B')\n",
    "model_dir = proj_dir / 'models' #location of model\n",
    "data_dir = proj_dir / 'RawData' #location of raw data\n",
    "output_dir = proj_dir / 'ProcessedData' #location of output data\n",
    "(output_dir).mkdir(exist_ok=True) #create output data folder\n",
    "\n",
    "!ls $proj_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify Config Files\n",
    "\n",
    "The Delta Pipeline is controlled using `.json` [config files](https://delta.readthedocs.io/en/latest/usage/config_desc.html). By default two config files are provide: one for 1D mother machine data: `config_mothermachine.json` and one for 2D (microcolony or flowcell) data: `config_2D.json`.\n",
    "\n",
    "You need to modify these config files to point Delta to the correct data folder.  \n",
    "We also need to specify the correct path to the pre-trained models.\n",
    "\n",
    "Here we will open the config file using the [`json`](https://docs.python.org/3/library/json.html) package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select config file to modify ('2D' or 'mothermachine'):\n",
    "config_filename = proj_dir / 'config_2D.json'\n",
    "with open(config_filename) as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to modify the relevant fields to point to the correct paths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Technical note: reminder: `delta` needs paths specified as strings, we can make a quick function to do this:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_str(posixpath):\n",
    "    return str(posixpath.resolve())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#point to model location\n",
    "config['model_file_seg'] = to_str(model_dir / 'unet_pads_seg.hdf5')    \n",
    "config['model_file_track'] = to_str(model_dir / 'unet_pads_track.hdf5')    \n",
    "\n",
    "#only needed for model training, in that case, point to location of training data\n",
    "config['training_set_seg'] = ''\n",
    "config['training_set_track'] = ''\n",
    "\n",
    "#point to raw data location\n",
    "config['eval_movie'] = to_str(data_dir)\n",
    "\n",
    "#specify output formats\n",
    "config['save_format'] = [\"pickle\", \"movie\"]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can write the config file back to disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_config_filename = proj_dir / 'config_2D_local.json'\n",
    "with open(new_config_filename, 'w') as f:\n",
    "    json.dump(config, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the pipeline\n",
    "\n",
    "Now we setup the pipeline, most importantly, you have to specify the naming format using the `xpreader` function.  \n",
    "See [here](https://delta.readthedocs.io/en/latest/usage/pipeline_desc.html) for detailed instructions. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config\n",
    "delta.config.load_config(new_config_filename)\n",
    "\n",
    "# set path to raw data to analyze:\n",
    "file_path = to_str(data_dir)\n",
    "\n",
    "# Init reader and specify file naming scheme\n",
    "xpreader = delta.utils.xpreader(\n",
    "            file_path,\n",
    "            prototype = 'Pos%03i_Frm%03i_Ch%02i.tif',\n",
    "            fileorder = 'ptc',\n",
    "            filenamesindexing=1\n",
    "            )\n",
    "\n",
    "# Print experiment parameters to make sure it initialized properly:\n",
    "print(\"\"\"Initialized experiment reader:\n",
    "    - %d positions\n",
    "    - %d imaging channels\n",
    "    - %d timepoints\"\"\"%(xpreader.positions, xpreader.channels, xpreader.timepoints)\n",
    ")\n",
    "\n",
    "# Init pipeline:\n",
    "xp = delta.pipeline.Pipeline(xpreader, resfolder=output_dir)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Pipeline on GPU\n",
    "Running the full analysis without a GPU takes a long time (150min on 2017 MacBook Pro with 2.8 GHz Quad-Core i7; using a RTX8000 GPU the same dataset is however processed in 3min!).\n",
    "\n",
    "If you have a GPU, you can run the code below. If you only have a CPU, you can save some time by going to the next section where we will only run first 4 frames and then download the pre-processed data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Pipeline\n",
    "xp.process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the output: we should have a `.mp4` movie for visual inspection, and a `.pkl` file containing all the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls $output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Step: Post-process Delta output\n",
    "Continue with the next notebook `2_post_processing_delta`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra material: Batch processing \n",
    "\n",
    "Above we processed only a single position. If you want to process multiple positions you have two options:\n",
    "\n",
    "1. Put all data in the same folder and indicate position in filename. This works well, but only works if all positions have exact same size. \n",
    "2. Loop over all positions. For this you can look at the provided notebook `extra_batch_script`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra material: CPU fallback\n",
    "\n",
    "**DO NOT RUN THIS SECTION if you already processed the full-pipeline above**\n",
    "\n",
    "If you have no GPU, you can use this section to just analyze the first 4 frames, so you can see the process. We will then load pre-processed data in the next notebook.\n",
    "\n",
    "Uncomment the code below to analyze the first 4 frames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xp.process(frames=list(range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we download pre-processed data if needed. Uncomment the lines below to download the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'results.zip'\n",
    "file_path = output_dir / file_name\n",
    "\n",
    "!wget -q  -O $file_path https://drive.switch.ch/index.php/s/8LBYv90PoThxh3r/download\n",
    "!(cd $output_dir && unzip -o -q -j $file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the output: we should have a `.mp4` movie for visual inspection, and a `.pkl` file containing all the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position000000.mp4 Position000000.pkl results.zip\n"
     ]
    }
   ],
   "source": [
    "!ls $output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can remove the zip file again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm $file_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('i2i_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "04885f21a4bd9418df205c8169dbf35b8c72791b69b584ac7513023d01d78b79"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

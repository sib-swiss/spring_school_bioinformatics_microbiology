{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Postprocess Delta Analysis\n",
    "\n",
    "We will now look at the output of Delta. For package info, please refer to the Project2A Notebook.\n",
    "\n",
    "You can also find a lot of extra info in the Delta documentation [here](https://delta.readthedocs.io/en/latest/usage/analysis.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages\n",
    "\n",
    "Before starting the code we need to import all the required packages.\n",
    "\n",
    "We use a number of important Python packages:\n",
    "- [Numpy](https://numpy.org): Goto package for vector/matrix based calculations (heavily inspired by Matlab)\n",
    "- [Pandas](https://pandas.pydata.org): Goto package for handling data tables (heavily inspired by R) \n",
    "- [Scipy](https://scipy.org): Numpy extensions for statistics, image analysis, and more\n",
    "- [Scikit-image (skimage)](https://scikit-image.org): Goto package for image analysis\n",
    "- [Matplotlib](https://matplotlib.org): Goto package for plotting data\n",
    "- [Napari](https://napari.org): GUI based interactive image viewer\n",
    "- [pathlib](https://docs.python.org/3/library/pathlib.html): Path handling made easy\n",
    "- [pickle](https://docs.python.org/3/library/pickle.html): Read pkl file format\n",
    "- [delta](https://delta.readthedocs.io/en/latest/usage/analysis.html): Delta pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%gui qt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "matplotlib.rc(\"figure\", figsize=(10,5))\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import pathlib\n",
    "import tifffile\n",
    "import pickle\n",
    "\n",
    "from skimage.measure import regionprops\n",
    "\n",
    "import napari\n",
    "from napari.utils.notebook_display import nbscreenshot\n",
    "\n",
    "import delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Folders\n",
    "As always we start with specifying the data paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_dir = pathlib.Path(pathlib.Path.home(), 'workdir', 'Project2B')\n",
    "processed_dir = proj_dir / 'ProcessedData'\n",
    "image_dir = proj_dir / 'RawData'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_str(posixpath):\n",
    "    return str(posixpath.resolve())    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "We can now load the data again. See [here](https://delta.readthedocs.io/en/latest/usage/analysis.html) for detailed instructions.\n",
    "To load all data we can use the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta.config.load_config(to_str(proj_dir / 'config_2D_local.json'))\n",
    "reader = delta.utilities.xpreader(image_dir, \n",
    "                                    prototype = 'Pos%03i_Frm%03i_Ch%02i.tif',\n",
    "                                    fileorder = 'ptc',\n",
    "                                    filenamesindexing=1\n",
    "                                    )\n",
    "processor = delta.pipeline.Pipeline(reader, reload=True, resfolder=to_str(processed_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can the access the position of choice as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = processor.positions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead we can also just directly load a single position:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find all position .pkl outputs:\n",
    "file_dirs = sorted(processed_dir.glob('*.pkl'))\n",
    "print(file_dirs)\n",
    "# this loads the processed data\n",
    "pos_name = to_str(file_dirs[0])\n",
    "pos = delta.pipeline.Position(None,None,None)\n",
    "pos.load(pos_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Segmentation with Napari\n",
    "\n",
    "We can add the image data and segmentation data to Napari to visually inspect them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imstack = np.stack(pos.rois[0].img_stack, axis=0) #load image data from position file\n",
    "labelstack = np.stack(pos.rois[0].label_stack, axis=0) #load label data from position file\n",
    "\n",
    "viewer = napari.view_image(imstack)\n",
    "viewer.add_labels(labelstack)\n",
    "viewer.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Cell Tracking Data\n",
    "\n",
    "All tracking info is stored in the [lineage object](https://delta.readthedocs.io/en/latest/usage/utils_desc.html#lineage). \n",
    "\n",
    "> **Exercise** \n",
    "> \n",
    "> Have a look the lineage class documentation and check what kind of information is stored\n",
    "\n",
    "We can also use the `keys` method to see what information is stored in the lineage object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin = pos.rois[0].lineage #get lineage for first region of interest (whole frame)\n",
    "cell_0 = lin.cells[0] #lineage info of first cell\n",
    "print('info stored in linegae object =', cell_0.keys()) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will plot the length of the cells present in the first frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_cells = lin.cellnumbers[0]\n",
    "for cell_id in first_cells:\n",
    "    cell = lin.cells[cell_id]\n",
    "    plt.plot(cell['frames'],cell['length'])\n",
    "plt.xlabel('frame #')\n",
    "plt.ylabel('length (pixels)')\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Tracking Data to Standard Format\n",
    "\n",
    "As you can clearly see from the saw-tooth pattern of cell length, a cell lineage in Delta is defined in a bit of a weird way as it continues across cell divisions. More commonly a cell lineage is defined to start at cell birth and stop and cell division. \n",
    "\n",
    "As a first step we thus have to split these lineages into segments.\n",
    "Below we give a function that does this (no need to try to understand this code for now)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_lineages(lin):\n",
    "    #first we give each sublineage a unique id\n",
    "    unique_count = 0 \n",
    "    #loop delta lineages\n",
    "    for cell in lin.cells:\n",
    "\n",
    "        ## create sublineage ID\n",
    "        #find division events\n",
    "        div_event = np.array([d is not None for d in cell['daughters']])\n",
    "        #cumulative number of divisions gives a unique nr to each segment\n",
    "        sublin_id = np.cumsum(div_event) \n",
    "        #now assign unique number accross all cell lineages\n",
    "        unique_id = sublin_id + unique_count #unique cells id\n",
    "        \n",
    "        #update unique_count \n",
    "        unique_count += (np.sum(div_event) + 1)\n",
    "        \n",
    "        #init output fields\n",
    "        empty_list = np.full_like(sublin_id, -1).tolist()\n",
    "        cell['lin_id'] = empty_list\n",
    "        cell['sublin_idx'] = empty_list\n",
    "        cell['mother_lin_id'] = empty_list\n",
    "        cell['d1_lin_id'] = empty_list\n",
    "        cell['d2_lin_id'] = empty_list\n",
    "        \n",
    "        ##now we have to connect lineages together\n",
    "        #find mother cell and birth frame\n",
    "        mom_idx = cell['mother'] #this is mother of delta lineage \n",
    "        birth_frm = cell['frames'][0]        \n",
    "        if mom_idx is not None:\n",
    "            mom = lin.cells[mom_idx] #get properties of mom\n",
    "            \n",
    "            try:\n",
    "                ## find unique cell id of the proper sub-segment in the mom lineage\n",
    "                div_frm = mom['frames'].index(birth_frm-1)\n",
    "                mom_lin_id = mom['lin_id'][div_frm] #this is proper unique lin id of mom\n",
    "                \n",
    "                ## we now want to add info of this d2 offspring to mother\n",
    "                #we extract frames of current segment in mom (between current and prev division)\n",
    "                div_events_mom = np.nonzero(np.array(mom['daughters'])[0:birth_frm])[0]\n",
    "                start_idx = div_events_mom[-1] if div_events_mom.size > 0 else 0\n",
    "                \n",
    "                #assign d2 lin number to correct frames\n",
    "                d2_temp = np.array(mom['d2_lin_id'])\n",
    "                d2_temp[start_idx:birth_frm] = unique_count                \n",
    "                mom['d2_lin_id'] = d2_temp.tolist()\n",
    "                \n",
    "            except:\n",
    "                mom_lin_id = -1\n",
    "        else:\n",
    "            #no mom found (first cell)\n",
    "             mom_lin_id = -1   \n",
    "                    \n",
    "        \n",
    "        ## add mother info\n",
    "        #the id of mother is the id of prev segment\n",
    "        mother_lin_id = unique_id.copy() - 1\n",
    "        #except for first segment, there we use the lin_index of mother we found above\n",
    "        mother_lin_id[sublin_id==0] = mom_lin_id\n",
    "        \n",
    "        #add d1 offspring number to linage \n",
    "        #this is simply next segment\n",
    "        d1_lin_id = unique_id.copy() + 1\n",
    "        #except for last segment, this does not have d1 offspring \n",
    "        d1_lin_id[d1_lin_id==d1_lin_id[-1]] = -1\n",
    "\n",
    "        #now we assign properties to cell\n",
    "        cell['sublin_idx'] = sublin_id.tolist()\n",
    "        cell['lin_id'] = unique_id.tolist()\n",
    "        cell['mother_lin_id'] = mother_lin_id.tolist()\n",
    "        cell['d1_lin_id'] = d1_lin_id.tolist()\n",
    "        \n",
    "    return None #lin is updated in place"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know apply this function, and can see we have added some new items to the linage object.\n",
    "\n",
    "Most importantly: the property `lin_id` now gives a unique number to each and every cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_lineages(lin) #call split lin function\n",
    "print('info stored in linegae object =', lin.cells[0].keys()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this plot each lineage separately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_cells = lin.cellnumbers[0]\n",
    "for cell_id in first_cells:\n",
    "    #current cell lineage\n",
    "    cell = lin.cells[cell_id]\n",
    "    \n",
    "    #convert lists to numpy arrays for easier manipulation\n",
    "    lin_id_vec = np.array(cell['lin_id'])\n",
    "    lin_frames = np.array(cell['frames'])\n",
    "    lin_length = np.array(cell['length'])\n",
    "    \n",
    "    #loop over all sublineages \n",
    "    for lin_id in np.unique(lin_id_vec):\n",
    "        #find frames of current sub-lin\n",
    "        curr_frames = lin_id_vec==lin_id\n",
    "        plt.plot(lin_frames[curr_frames],lin_length[curr_frames])\n",
    "plt.xlabel('frame #')\n",
    "plt.ylabel('length (pixels)')\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Positional Information\n",
    "\n",
    "If you have another look at the lineage object you can see it does not contain information on the location of cells. We add a function below to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_segment_info(lin, label_stack):\n",
    "    #lin: delta linage object\n",
    "    #label_stack: list of label images = pos.rois[0].label_stack\n",
    "   \n",
    "    #initialize new property keys:\n",
    "    for cells in lin.cells:\n",
    "        cells.setdefault('x_pos',[])\n",
    "        cells.setdefault('y_pos',[])\n",
    "   \n",
    "    #loop frames\n",
    "    for label_im in label_stack:\n",
    "        #get region properties\n",
    "        rp_list = regionprops(label_im)\n",
    "        \n",
    "        #assign cell phenotypes\n",
    "        for idx, rp in enumerate(rp_list):\n",
    "            #get lineage number of cell (note labels are 1 based, cell lineages are 0 based!)\n",
    "            cell_idx = rp.label-1\n",
    "            #assign phenotypes\n",
    "            lin.cells[cell_idx]['x_pos'].append(rp.centroid[1]) #order in centroid is (y,x)\n",
    "            lin.cells[cell_idx]['y_pos'].append(rp.centroid[0]) #order in centroid is (y,x)\n",
    "                    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know apply this function, and can see we have added some new items to the linage object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_segment_info(lin, pos.rois[0].label_stack) #call split lin function\n",
    "print('info stored in linegae object =', lin.cells[0].keys()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is always good to check things visually. Below we define a function that can be used to plot any cell property of choice as a spatial map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spatial_map(pos, lin, property, frame=-1, axis=None):\n",
    "   #pos: delta position object\n",
    "   #lin: delta linage object\n",
    "   #property: key of cell property contained in lineage object\n",
    "   #frame: frame to show, if not specified last one is chosen\n",
    "   #axis: axis to add plot to, if not specified new one is made\n",
    "   \n",
    "   #create color map where Nan is shown as black  \n",
    "   colMap = cm.get_cmap(\"viridis\").copy()\n",
    "   colMap.set_bad(color='black')\n",
    "   \n",
    "   #get frame\n",
    "   frame = len(pos.rois[0].label_stack)-1 if frame==-1 else frame\n",
    "\n",
    "   # get label image:\n",
    "   labels = pos.rois[0].label_stack[frame]\n",
    "\n",
    "   spatial_map = np.full(labels.shape, np.nan)\n",
    "\n",
    "   # Go over cells in selected frame:\n",
    "   for cnb in lin.cellnumbers[frame]:\n",
    "   \n",
    "      #convert to numpy to allow for advanced indexing\n",
    "      cell_frames = np.array(lin.cells[cnb]['frames'])\n",
    "      cell_prop = np.array(lin.cells[cnb][property])\n",
    "   \n",
    "      #frame index      \n",
    "      fr_idx = cell_frames==frame\n",
    "      cell_prop = cell_prop[fr_idx]\n",
    "      \n",
    "      #assign cells mask area the phenotype of choice\n",
    "      spatial_map[labels==cnb+1] = cell_prop\n",
    "\n",
    "   #create new axis if needed\n",
    "   if axis is None:\n",
    "      fig, axis = plt.subplots()\n",
    "   \n",
    "   #make plot\n",
    "   axis.imshow(spatial_map, cmap=colMap)\n",
    "   axis.set_xlabel('x-pos') \n",
    "   axis.set_ylabel('y-pos') \n",
    "   axis.set_title(property)\n",
    "   \n",
    "   return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2,figsize=(16,24))\n",
    "plot_spatial_map(pos, lin, 'x_pos', axis=axs[0])\n",
    "plot_spatial_map(pos, lin, 'y_pos', frame=-1, axis=axs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Technical note*\n",
    "\n",
    "*The phase contrast images are stored within the delta position object.  \n",
    "You can access them with: `pos.rois[0].img_stack` which returns a list of 2D images, so to get the image from frame `f` you can use: `ph_im = pos.rois[0].img_stack[f]`.*\n",
    "\n",
    "*The fluorescent images are not stored however, and you will need to read them from disk if you ever need them (e.g. if you want to do proper shading & background corrections before extracting fluorescent intensities for precise quantification).*\n",
    "\n",
    "*You can use Delta's [`xpreader`](https://delta.readthedocs.io/en/latest/usage/utils_desc.html#the-xpreader-class) class to find the file name of the pictures: `tiff_name = reader.getfilenamefromprototype(pos_idx,ch_idx,frm_idx)`.*  \n",
    "Then you can read the image file using `tifffile.imread(tiff_name)`*\n",
    "\n",
    "*For now we just use Delta's default fluorescent values, but we provide a modified version of the `add_segment_info` function below (called `add_cell_info`) that you could modify in the future incase you need to implement proper image corrections.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_cell_info(lin, label_stack, reader):\n",
    "    #lin: delta linage object\n",
    "    #label_stack: list of label images = pos.rois[0].label_stack\n",
    "    #reader: delta_xp reader object\n",
    "    \n",
    "    #get number of channels\n",
    "    n_ch = reader.channels\n",
    "    n_fluor = n_ch - 1\n",
    "    \n",
    "    #create channel names\n",
    "    ch_names_av = ['fluor%i' % ch for ch in range(n_ch)]\n",
    "    ch_names_cor = ['cor_fluor%i' % ch for ch in range(n_ch)]\n",
    "    ch_names_tot = ['tot_fluor%i' % ch for ch in range(n_ch)]\n",
    "\n",
    "    \n",
    "    #initialize new property keys:\n",
    "    for cells in lin.cells:\n",
    "        cells.setdefault('x_pos',[])\n",
    "        cells.setdefault('y_pos',[])\n",
    "        for ch in range(n_fluor):\n",
    "            cells.setdefault(ch_names_av[ch],[])\n",
    "            cells.setdefault(ch_names_tot[ch],[])\n",
    "    \n",
    "    #loop frames\n",
    "    for fr, label_im in enumerate(label_stack):\n",
    "        #load fluorescent images\n",
    "        fluor_im_list = [] \n",
    "        for ch in range(n_fluor):\n",
    "            #read image\n",
    "            tiff_name = reader.getfilenamefromprototype(0,ch+1,fr) \n",
    "            fluor_im = tifffile.imread(tiff_name)\n",
    "            # \n",
    "            # insert code here for shading correction etc.\n",
    "            # fluor_im = function_for_shading_correction(fluor_im)\n",
    "            # this code would do something like: corrected_im = fluor_im / shading_im\n",
    "            # where shading image is an image taken with an homogenous sample. It's intensity thus reflects the intensity of the light field\n",
    "            #\n",
    "            fluor_im_list.append(fluor_im)\n",
    "        \n",
    "        #combine in multichannel image\n",
    "        multi_ch = np.stack(fluor_im_list, axis=-1)\n",
    "        \n",
    "        #get region properties\n",
    "        rp_list = regionprops(label_im, intensity_image=multi_ch)\n",
    "        \n",
    "        #assign cell phenotypes\n",
    "        for idx, rp in enumerate(rp_list):\n",
    "            #get lineage number of cell (note labels are 1 based, cell lineages are 0 based!)\n",
    "            cell_idx = rp.label-1\n",
    "            \n",
    "            #assign phenotypes\n",
    "            #for example we can add position info, or any other region props property\n",
    "            lin.cells[cell_idx]['x_pos'].append(rp.centroid[1]) #order in centroid is (y,x)\n",
    "            lin.cells[cell_idx]['y_pos'].append(rp.centroid[0]) #order in centroid is (y,x)\n",
    "            \n",
    "            #now assign fluorescent values\n",
    "            for ch in range(n_fluor):\n",
    "                #get mean fluorescent intensity\n",
    "                mean_I = rp.intensity_mean[ch]\n",
    "                #get total fluorescent intensity\n",
    "                tot_I = rp.intensity_mean[ch] * rp.num_pixels\n",
    "                \n",
    "                # insert code here for background correction\n",
    "                # bg_signal = function_to_extract_bg_intensity(fluor_im, label_im)\n",
    "                #option 1: simple substraction (works best if bg_signal-dark_signal is very low)\n",
    "                # corr_I = mean_I - bg_signal \n",
    "                #option 2: fold-change ratio (works best when bg_signal-dark_signal is not too close to 0)\n",
    "                # corr_I = (mean_I - dark_signal) / (bg_signal - dark_signal) \n",
    "                # the dark_signal is the median intensity of image taken with closed shutter\n",
    "                # the bg_signal is the median intensity in pixels that do not belong to cells\n",
    "            \n",
    "                #store values\n",
    "                lin.cells[cell_idx][ch_names_av[ch]].append(mean_I) #mean intensity\n",
    "                lin.cells[cell_idx][ch_names_tot[ch]].append(tot_I) #total intensity\n",
    "                #lin.cells[cell_idx][ch_names_cor[ch]].append(corr_I) #corrected mean intensity\n",
    "                    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then convert the list of dictonaries to a pandas data frame:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to Pandas dataframe\n",
    "\n",
    "Now that we have all the important cell properties we can convert the Delta output to a Pandas dataframe. We provide a function for this below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_to_df(lin):\n",
    "    #find vector based data (only vector based data is compatible with dataframe)\n",
    "    vector_data = []\n",
    "    [vector_data.append(key) for key in lin.cells[0].keys() if isinstance(lin.cells[0][key], list)]\n",
    "    #create data frame\n",
    "    df = pd.DataFrame(lin.cells) \n",
    "    #this creates nested dataframe, we need to explode time into separate rows:\n",
    "    df = df.explode(vector_data)\n",
    "    #and reindex\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = lin_to_df(lin)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All-in-one processing\n",
    "\n",
    "For future use, we provide here a single wrapper function that takes as entry a delta position object and outputs a Pandas dataframe by successively calling the functions we defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta_to_df(pos, reader=None):\n",
    "    \n",
    "    lin = pos.rois[0].lineage\n",
    "    \n",
    "    #split lineages:\n",
    "    split_lineages(lin)\n",
    "    \n",
    "    #add segment info\n",
    "    add_segment_info(lin, pos.rois[0].label_stack)\n",
    "    \n",
    "    #alternatively you can the add_cell_info function to include proper image correction\n",
    "    #add_cell_info(lin, pos.rois[0].label_stack, reader)\n",
    "    \n",
    "    #convert to pandas dataframe\n",
    "    df = lin_to_df(lin)\n",
    "   \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's first reload the position\n",
    "pos = delta.pipeline.Position(None,None,None)\n",
    "pos.load(pos_name)\n",
    "\n",
    "df = delta_to_df(pos)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Saving\n",
    "This would be a good time to save your data.  \n",
    "You can save the position file using `pos.save(filename=filename, save_format='pickle')`. We won't do this now as we do not want to accidentally corrupt our data.\n",
    "\n",
    "Instead we just save the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_name = processed_dir / pos_name.replace('.pkl','_df.pkl')\n",
    "df.to_pickle(save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we save the updated lineage info:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_name = processed_dir / pos_name.replace('.pkl','_updated_lin.pkl')\n",
    "filehandler = open(save_name, 'wb') \n",
    "pickle.dump(lin, filehandler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Tracking with Napari\n",
    "\n",
    "Now that we have the dataframe we can add the trackign info to Napari to check it visually.\n",
    "\n",
    "For that we use the Napari [tracks layer](https://napari.org/howtos/layers/tracks.html).  \n",
    "To use it we need to specify tracking data in a specific format  (see documentation above):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create matrix with lin_id, and (t,x,y) coordinates\n",
    "lin_data = np.vstack([df[\"lin_id\"].to_numpy(dtype=int), \n",
    "                      df[\"frames\"].to_numpy(dtype=int), \n",
    "                      df[\"y_pos\"].to_numpy(dtype=int), \n",
    "                      df[\"x_pos\"].to_numpy(dtype=int)]).T\n",
    "lin_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dictionary that link lin_id of cell to lin_id of mother \n",
    "lin_id = df[\"lin_id\"].to_numpy(dtype=int)\n",
    "mom_id = df[\"mother_lin_id\"].to_numpy(dtype=int)\n",
    "\n",
    "#lin_id is a vector that contains many duplicate entries, we remove them using np.unique:\n",
    "lin_set, idx_set = np.unique(lin_id, return_index=True)\n",
    "mom_set = mom_id[idx_set]\n",
    "\n",
    "#init graph dictionary\n",
    "graph = {}\n",
    "for linnum, mom in zip(lin_set, mom_set):\n",
    "    if mom >= 0:\n",
    "        graph[linnum] = mom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add tracks to viewer\n",
    "viewer.add_tracks(lin_data, name='Tracks', graph=graph)\n",
    "viewer.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Step: Explore data\n",
    "\n",
    "**Before the next step the Tutors will give an introduction, if you are ready for this step please let them know!**\n",
    "\n",
    "We continue in the next notebook `3_explore_data_delta`"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6cb765ee22dcc904efaf1351ec4408646fdaf0eb2968a618fbd04b98f5406910"
  },
  "kernelspec": {
   "display_name": "Python [conda env:i2i_p1_env]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

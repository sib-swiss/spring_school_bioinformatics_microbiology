{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Postprocessing Ilastik Segmentation - 3 Classes\n",
    "This notebook post processes a 3 classes Ilastik segmentation:\n",
    "\n",
    "- Class/Label 1: Cell centers\n",
    "- Class/Label 2: Background\n",
    "- Class/Label 3: Cell-edges\n",
    "\n",
    "Cell-edges should be about 1-pixel wide line that marks the edge of the cell.  \n",
    "Cell centers should label the cell interior\n",
    "\n",
    "We will use the Cell centers class to find markers (center points) for the watershed.  \n",
    "The total cell mask is taken from the sum of Class 1 and 3 i.e. P(pixel=cell) = P(pixel=edge) + P(pixel=cell center) \n",
    "\n",
    "This is how the training labels should look like:\n",
    "![training labels](Ilastik_3ClassSeg_TrainingPoints.png)\n",
    "\n",
    "This is how the Ilastik prediction should look like:\n",
    "![ilastik output](Ilastik_3ClassSeg_Output.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "#next two lines make sure that Matplotlib plots are shown properly in Jupyter Notebook\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "#next line is required for Napari\n",
    "%gui qt\n",
    "\n",
    "#main data analysis packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#image processing packages\n",
    "from scipy import ndimage as ndi\n",
    "import skimage.segmentation as segmentation \n",
    "import skimage.filters as filters\n",
    "from skimage.measure import label, regionprops, regionprops_table\n",
    "from skimage import morphology\n",
    "from skimage.future import graph\n",
    "\n",
    "\n",
    "#data plotting packages\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "#set default figure size\n",
    "matplotlib.rc(\"figure\", figsize=(10,5))\n",
    "import seaborn as sns\n",
    "\n",
    "#image viewer\n",
    "import napari\n",
    "from napari.utils.notebook_display import nbscreenshot\n",
    "\n",
    "#out of memory computation\n",
    "from dask_image.imread import imread\n",
    "import dask.array as da\n",
    "\n",
    "#path handling\n",
    "import pathlib\n",
    "\n",
    "#file handling\n",
    "import h5py\n",
    "\n",
    "#Instead of dask_image.imread.imread() you can also use tifffile.imread() to directly read images into memory\n",
    "#import tifffile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we initiate a cashe for Dask to speed up repeated computation (important for working with Napari)\n",
    "from dask.cache import Cache\n",
    "cache = Cache(2e9)  # Leverage two gigabytes of memory\n",
    "cache.register()    # Turn cache on globally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Import and visualize Ilastik output\n",
    "### Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the path to the folder that contains project data\n",
    "root = pathlib.Path(pathlib.Path.home(), 'Andreas', 'Training')\n",
    "\n",
    "#raw images\n",
    "im_name0 = 'ph_training.tif' #set name of image\n",
    "im_name1 = 'gfp_training.tif' #set name of image\n",
    "\n",
    "#ilastik output\n",
    "segment_name = 'training_pr_Probabilities.h5' #set name of segmented data\n",
    "\n",
    "#ilastik settings\n",
    "fg_idx = 0 #set index of foreground label used in Ilastik\n",
    "edge_idx = 2 #set index of edge in Ilastik\n",
    "\n",
    "im0_stack = imread(root / im_name0) #load image with dask-image for out of memory processing \n",
    "im1_stack = imread(root / im_name1) #load image with dask-image for out of memory processing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize the data we will use [Napari](https://napari.org), that allows for interactive image visualization. \n",
    "You can use the slider at the bottom of the window to scroll trough time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup napari viewer, with 2 channel image\n",
    "viewer = napari.view_image(im0_stack, name=\"phase\", colormap=\"gray\")\n",
    "viewer.add_image(im1_stack, name=\"rfp\", colormap=\"red\", opacity=0.5)\n",
    "napari.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and visualize Ilastik output\n",
    "Next we load the data exported by Ilastik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_path = root / segment_name #path to Ilastik output\n",
    "seg_data = h5py.File(seg_path, 'r') #open \n",
    "\n",
    "#we again use Dask to load the data out of memory\n",
    "#technical comment: we set chunk size to be equal to the size of single frame. \n",
    "chuck_size = (1, 3, *im0_stack.shape[-2:])\n",
    "seg_prob = da.from_array(seg_data['exported_data'], chunks=chuck_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Convert Ilastik probability map into segmentation\n",
    "Ilastik assigns to each pixel the probability that it belongs to a cell. We need to convert this to in instance based segmentation, where each cell is assigned a unique label. This requires a number of steps:\n",
    "1. Pre-process probability map using filters\n",
    "2. Convert probability map to semantic segmentation (binary image where cells=1 and background=0) using thresholding\n",
    "3. Clean up semantic segmentation using morphological operations\n",
    "4. Convert semantic segmentation into instance segmentation (integer images where each cells has own label)\n",
    "5. Post-process instance segmentation by separating merged cells using watershed algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 1. Pre-process probability map using filters\n",
    "\n",
    "As a first step probability maps are often processed using a Gaussian blur filter using a small (~1 pixel) size, to ensure that the probability maps are locally smooth. We will use scikit image [`filters.gaussion`](https://scikit-image.org/docs/stable/api/skimage.filters.html) to do this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do not smooth edge\n",
    "p_edge = seg_prob[:,edge_idx,:,:]\n",
    "\n",
    "#smooth total cell probability\n",
    "sigma = 1\n",
    "p_cell = seg_prob[:,fg_idx,:,:] + seg_prob[:,edge_idx,:,:] \n",
    "p_cell = da.map_blocks(filters.gaussian, p_cell, sigma, channel_axis=0)\n",
    "\n",
    "#smooth cell centre\n",
    "sigma = 1 #size of Gaussion kernel to use \n",
    "p_center = da.map_blocks(filters.gaussian, seg_prob[:,fg_idx,:,:], sigma, channel_axis=0)\n",
    "\n",
    "#add probability layer to Napari Viewer\n",
    "prop_layer = viewer.add_image(p_center, name='p_center',colormap='gray')\n",
    "prop_layer = viewer.add_image(p_edge, name='p_edge',colormap='gray')\n",
    "prop_layer = viewer.add_image(p_cell, name='p_cell',colormap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### 2. Convert probability map to semantic segmentation using thresholding\n",
    "Here we test good threshold for cell centre and full cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create array with all threshold values to rry, here we use 0,0.01,0.02,...,1\n",
    "thresholds_to_try = np.linspace(0,1,101)\n",
    "\n",
    "#convert the list of 3D stacks to a single 4D stack\n",
    "marker_stack = da.stack([p_center > t for t in thresholds_to_try], axis=0)\n",
    "mask_stack = da.stack([p_cell > t for t in thresholds_to_try], axis=0)\n",
    "\n",
    "#add to viewer\n",
    "mask_layer_int = viewer.add_image(mask_stack, name='cell masks',colormap='gray')\n",
    "marker_layer_int = viewer.add_image(marker_stack, name='cell markers',colormap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose your favorite method or enter a manually chosen value\n",
    "tr_marker = 0.4\n",
    "tr_mask = 0.5\n",
    "\n",
    "#threshold cell markers (centre points) and cell masks\n",
    "markers = p_center > tr_marker\n",
    "mask = p_cell > tr_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### 3. Clean up semantic segmentation using morphological operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_hole_size = 40 # maximum area of holes that will be filled (in pixels)\n",
    "min_cell_size = 50 # minimum area of objects to keep (in pixels)\n",
    "\n",
    "#clean up cell masks\n",
    "mask = da.map_blocks(morphology.remove_small_holes, mask, max_hole_size)\n",
    "mask = da.map_blocks(morphology.remove_small_objects, mask, min_cell_size)\n",
    "\n",
    "#add mask to Napari\n",
    "mask_layer_clean = viewer.add_image(mask, name='mask cleaned',colormap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Convert semantic segmentation into instance segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert binary markers into label markers:\n",
    "marker_labels = da.map_blocks(label, markers)\n",
    "\n",
    "#add markers to Napari\n",
    "nap_marker_labels = viewer.add_labels(marker_labels, name='marker_labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 5. Watershed algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need a wrapper function to tranform named arguments into positional arguments to make things work with Dask\n",
    "def watershed(dist, markers, mask):\n",
    "    return segmentation.watershed(-dist, markers=markers, mask=mask)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate distance to edge of mask\n",
    "dist_transform = da.map_blocks(ndi.distance_transform_edt, mask)   \n",
    "nap_dist = viewer.add_image(dist_transform, name='dist_trans')\n",
    "\n",
    "#run watershed\n",
    "watershed_labels = da.map_blocks(watershed, dist_transform, marker_labels, mask, chunks=(1,*mask.shape[-2:]))\n",
    "\n",
    "#add to Napari\n",
    "nap_watershed_labels = viewer.add_labels(watershed_labels, name='after watershed')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### SKIP: RAG Recombine Cells\n",
    "\n",
    "[Region Adjacency Graphs](https://scikit-image.org/docs/stable/api/skimage.future.graph.html) could potentially be used to correct the over segmentation that results from the Watershed.\n",
    "The parameters below need optimization, but if watershed worked well this step can be skipped and cells can be merged manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we go into memory now\n",
    "# watershed_labels = watershed_labels.compute()\n",
    "# p_edge = p_edge.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels_merged = np.empty_like(watershed_labels)\n",
    "\n",
    "# for idx, (lab, edg) in enumerate(zip(watershed_labels, p_edge)):\n",
    "#     rag = graph.rag.rag_boundary(lab, edg, connectivity=2)\n",
    "#     labels_merged[idx,:,:] = graph.cut_threshold(lab, rag, 0.4, in_place=False) #used 0.88 for large set\n",
    "\n",
    "#add to Napari\n",
    "#nap_merged_labels = viewer.add_labels(labels_merged, name='after merging')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Store segmentation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can first convert to 16bit to save some space\n",
    "watershed_labels.astype('int16')\n",
    "outname = root /  'processed_labels.hdf5'\n",
    "\n",
    "#store as hdf5\n",
    "h5f = h5py.File(outname, 'w')\n",
    "h5f.create_dataset('raw_labels', data=watershed_labels)\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Manual Correction\n",
    "\n",
    "See notebook manual_correct_segment"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "interpreter": {
   "hash": "04885f21a4bd9418df205c8169dbf35b8c72791b69b584ac7513023d01d78b79"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('i2i_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Correct Ilastik Segmentation\n",
    "Here we wil use Napari to manually correct segmentation.\n",
    "See documentation [here](https://napari.org/howtos/layers/labels.html)\n",
    "\n",
    "Note that the keyboard shortcuts in the documentations are wrong!  \n",
    "See below for details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "#next line is required for Napari\n",
    "%gui qt\n",
    "\n",
    "#main data analysis packages\n",
    "import numpy as np\n",
    "\n",
    "#image viewer\n",
    "import napari\n",
    "from napari.utils.notebook_display import nbscreenshot\n",
    "\n",
    "#out of memory computation\n",
    "from dask_image.imread import imread\n",
    "import dask.array as da\n",
    "\n",
    "#path handling\n",
    "import pathlib\n",
    "\n",
    "#file handling\n",
    "import h5py\n",
    "\n",
    "#Instead of dask_image.imread.imread() you can also use tifffile.imread() to directly read images into memory\n",
    "#import tifffile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we initiate a cashe for Dask to speed up repeated computation (important for working with Napari)\n",
    "from dask.cache import Cache\n",
    "cache = Cache(2e9)  # Leverage two gigabytes of memory\n",
    "cache.register()    # Turn cache on globally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the path to the folder that contains project data\n",
    "root = pathlib.Path(pathlib.Path.home(), 'Andreas', 'Training')\n",
    "\n",
    "#raw images\n",
    "im_name0 = 'ph_training.tif' #set name of image\n",
    "im_name1 = 'gfp_training.tif' #set name of image\n",
    "\n",
    "#segmentation output\n",
    "seg_file_name = root / 'processed_labels.hdf5'\n",
    "seg_file_name_corr = root / 'processed_labels_corrected.hdf5'\n",
    "\n",
    "\n",
    "im0_stack = imread(root / im_name0) #load image with dask-image for out of memory processing \n",
    "im1_stack = imread(root / im_name1) #load image with dask-image for out of memory processing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize the data we will use [Napari](https://napari.org), that allows for interactive image visualization. \n",
    "You can use the slider at the bottom of the window to scroll trough time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup napari viewer, with 2 channel image\n",
    "viewer = napari.view_image(im0_stack, name=\"phase\", colormap=\"gray\")\n",
    "viewer.add_image(im1_stack, name=\"rfp\", colormap=\"red\", opacity=0.5)\n",
    "napari.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Manual Correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we initialize manual correction or load existing file from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load manual correction\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#load processed segmentation if possible\n",
    "if not seg_file_name_corr.exists():\n",
    "    #load original segmentation\n",
    "    with h5py.File(seg_file_name, 'r') as f:\n",
    "        watershed_labels = np.array(f['raw_labels'])\n",
    "    \n",
    "    #initialize new corrected layer\n",
    "    print('Initialize manual correction')\n",
    "    frame_status = np.full(watershed_labels.shape[0], -1)\n",
    "    corrected_labels = watershed_labels.copy()\n",
    "else:\n",
    "    #load existing correction file\n",
    "    print('Load manual correction')\n",
    "    with h5py.File(seg_file_name_corr, 'r') as f:\n",
    "        frame_status = np.array(f['frame_status'])\n",
    "        corrected_labels = np.array(f['corrected_labels'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_corrected_labels = viewer.add_labels(corrected_labels, name='processed')\n",
    "np_corrected_labels.visible = True "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the default key bindings:\n",
    "\n",
    "- 1 = eraser\n",
    "- 2 = brush\n",
    "- 3 = paint-bucket\n",
    "- 4 = color picker\n",
    "- 5 = zoom/pan mode\n",
    "- M = select new color label (that is not yet in use)\n",
    "- arrow left/right: switch frames\n",
    "\n",
    "In addition we setup some new key bindings:\n",
    "- a = mark frame as corrected, store data and go to next frame\n",
    "- d = mark frame to discard later, store data and go to next frame\n",
    "- n = go to first unchecked frame\n",
    "- ` = toggle label layer visibility\n",
    "- b = save data\n",
    "- 8 = set brush to small size (1 pixel)\n",
    "- 9 = set brush to medium size\n",
    "- 0 = set brush to large size\n",
    "- [ = decrease brush size\n",
    "- ] = increase brush size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now go through each frame, if possible correct segmentation and press `a` when done to make frame as corrected.  \n",
    "If segmentation/image quality is too bad press `d` to mark frame to be discarded at end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_corrected_segementation():\n",
    "    with h5py.File(seg_file_name_corr, 'w') as f:\n",
    "        f.create_dataset('corrected_labels', data=corrected_labels)\n",
    "        f.create_dataset('frame_status', data=frame_status)\n",
    "    print('data saved')\n",
    "\n",
    "@viewer.bind_key('n', overwrite=True)\n",
    "def next_unprocessed_frame(viewer):\n",
    "    next_fr = np.where(frame_status == -1)[0][0]\n",
    "    viewer.dims.current_step = (next_fr, *viewer.dims.current_step[1:])\n",
    "\n",
    "@viewer.bind_key('a', overwrite=True)\n",
    "def skip_frame(viewer):\n",
    "    frame_status[viewer.dims.current_step[0]] = 1\n",
    "    print('approved frame %i' % viewer.dims.current_step[0])\n",
    "    save_corrected_segementation()\n",
    "    viewer.dims.current_step = (viewer.dims.current_step[0]+1, *viewer.dims.current_step[1:])\n",
    "    \n",
    "@viewer.bind_key('d', overwrite=True)\n",
    "def skip_frame(viewer):\n",
    "    frame_status[viewer.dims.current_step[0]] = 0 \n",
    "    print('discard frame %i' % viewer.dims.current_step[0])\n",
    "    save_corrected_segementation()\n",
    "    viewer.dims.current_step = (viewer.dims.current_step[0]+1, *viewer.dims.current_step[1:])\n",
    "        \n",
    "@viewer.bind_key('`', overwrite=True)\n",
    "def skip_frame(viewer):\n",
    "    np_corrected_labels.visible = not np_corrected_labels.visible   \n",
    "    \n",
    "@viewer.bind_key('b', overwrite=True)    \n",
    "def save_data(viewer):\n",
    "    save_corrected_segementation()\n",
    "    \n",
    "@viewer.bind_key('8', overwrite=True)    \n",
    "def set_brush_small(viewer):\n",
    "    np_corrected_labels.brush_size = 1\n",
    "\n",
    "@viewer.bind_key('9', overwrite=True)    \n",
    "def set_brush_med(viewer):\n",
    "    np_corrected_labels.brush_size = 5\n",
    "    \n",
    "@viewer.bind_key('0', overwrite=True)    \n",
    "def set_brush_large(viewer):\n",
    "    np_corrected_labels.brush_size = 20  \n",
    "   \n",
    "@viewer.bind_key(']', overwrite=True)    \n",
    "def increase_brush(viewer):\n",
    "    np_corrected_labels.brush_size += 1     \n",
    "    \n",
    "@viewer.bind_key('[', overwrite=True)    \n",
    "def decrease_brush(viewer):\n",
    "    np_corrected_labels.brush_size -= 1  \n",
    "    np_corrected_labels.brush_size = max(np_corrected_labels.brush_size, 1)\n",
    " \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_file = root /  'processed_labels_fully_corrected_2022-06-15.hdf5'\n",
    "\n",
    "with h5py.File(processed_file, 'w') as f:\n",
    "    f.create_dataset('corrected_labels', data=corrected_labels)\n",
    "    f.create_dataset('frame_status', data=frame_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114 114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-17 20:32:59.556 python[9832:648406] AdjustToIronwoodHotKeyChange - CG (hotmod:1) HotKey : hotKey enabled = 1, keyChar=0xfffbffff, virtKey=0x40000, flags=0x0 \n"
     ]
    }
   ],
   "source": [
    "training_im = im0_stack[frame_status==1,:,:]\n",
    "approved_labels = corrected_labels[frame_status==1,:,:]\n",
    "\n",
    "print(training_im.shape[0], approved_labels.shape[0])\n",
    "training_file = root /  'training_data.hdf5'\n",
    "with h5py.File(training_file, 'w') as f:\n",
    "    f.create_dataset('label', data=approved_labels)\n",
    "    f.create_dataset('images', data=training_im)\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "interpreter": {
   "hash": "04885f21a4bd9418df205c8169dbf35b8c72791b69b584ac7513023d01d78b79"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('i2i_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
